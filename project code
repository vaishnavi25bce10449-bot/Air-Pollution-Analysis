import pandas as pd
import matplotlib.pyplot as plt
# For Colab-specific file handling
from google.colab import files
import io 

# --- START: Colab-Specific File Loading ---

print("Uploading the dataset...")
# This line prompts a file selection window in Colab
uploaded = files.upload()

# The uploaded dictionary contains the filename and content.
# Assuming the user uploads 'delhi_air_quality.csv'
file_name = "delhi_air_quality.csv" 

if file_name in uploaded:
    # Read the file content from the in-memory dictionary
    df = pd.read_csv(io.StringIO(uploaded[file_name].decode('utf-8')))
    print(f"\nâœ… Successfully loaded {file_name}.")
else:
    # Fallback or error if the user uploads a different file
    print(f"\nâŒ Could not find {file_name}. Please check the file name.")
    # You might want to exit or load a dummy DataFrame here.
    # For simplicity, we assume success for the rest of the code.
    # If the user is expected to upload a different file, adjust `file_name`.
    pass
    
# --- END: Colab-Specific File Loading ---

# Step 2: Understanding the dataset
print("\nðŸ“Œ Dataset Info:")
print(df.info())

print("\nðŸ“Œ First 5 rows:")
print(df.head())

# Convert Date column to datetime format (if available)
# Using case-insensitive check for robustness, as column names can vary (e.g., 'Date' or 'date')
date_col = next((col for col in df.columns if col.lower() == 'date'), None)

if date_col:
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce') # 'coerce' turns invalid parsing into NaT
    df.set_index(date_col, inplace=True)

# Step 3: Check for missing values
print("\nðŸ“Œ Missing Values in Dataset:")
print(df.isnull().sum())

# Fill missing values with column mean
df.fillna(df.mean(numeric_only=True), inplace=True)

# Step 4: Basic statistics
print("\nðŸ“Œ Pollutant Statistics:")
print(df.describe())

# Step 5: Yearly/Monthly PM2.5 Trend
if 'PM2.5' in df.columns:
    plt.figure(figsize=(10, 6)) # Added figure size for better visualization in Colab
    df['PM2.5'].resample('M').mean().plot()
    plt.title("Monthly Average PM2.5 Levels in Delhi")
    plt.xlabel("Year")
    plt.ylabel("PM2.5 concentration (Âµg/mÂ³)")
    plt.grid(True) # Added grid for readability
    plt.show()

# Step 6: Correlation Heatmap
# Using a try/except block to handle cases where there might not be enough numeric columns after cleaning
try:
    numeric_df = df.select_dtypes(include=['float64', 'int64'])
    if numeric_df.shape[1] > 1:
        corr = numeric_df.corr()
        print("\nðŸ“Œ Pollutant Correlation Matrix:")
        print(corr)

        plt.figure(figsize=(10, 8)) # Added figure size
        plt.matshow(corr, fignum=1) # Specify fignum to use the defined figure
        plt.title("Pollutant Correlation Heatmap", y=1.1)
        
        # Add labels to the heatmap
        plt.xticks(range(numeric_df.shape[1]), numeric_df.columns, rotation=90)
        plt.yticks(range(numeric_df.shape[1]), numeric_df.columns)
        
        plt.colorbar()
        plt.show()
    else:
        print("\nSkipping Correlation Heatmap: Not enough numeric columns.")
except Exception as e:
    print(f"\nError generating Correlation Heatmap: {e}")


# Step 7: AQI Category based on PM2.5
def get_aqi_category(pm25):
    if pm25 <= 50: return "Good"
    elif pm25 <= 100: return "Satisfactory"
    elif pm25 <= 200: return "Moderate"
    elif pm25 <= 300: return "Poor"
    elif pm25 <= 400: return "Very Poor"
    else: return "Severe"

if 'PM2.5' in df.columns:
    df['AQI_Category'] = df['PM2.5'].apply(get_aqi_category)

    print("\nðŸ“Œ AQI Category Count:")
    print(df['AQI_Category'].value_counts())

    plt.figure(figsize=(10, 6)) # Added figure size
    df['AQI_Category'].value_counts().plot(kind='bar')
    plt.title("Delhi Air Quality Index Category Distribution")
    plt.xlabel("AQI Category")
    plt.ylabel("Count")
    plt.xticks(rotation=45) # Rotate x-labels for better fit
    plt.grid(axis='y', linestyle='--')
    plt.show()
